{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64ebf336",
   "metadata": {},
   "source": [
    "Mit diesem Jupyter Notbook werden bibl. Daten der Manifestationsebene von der SRU-K10plus-Schnittstelle http://sru.k10plus.de/opac-de-627 abgerufen und Datenfelder der SRU-Antwort mit Hilfe von XPath-Abfragen gezielt durchsucht sowie deren Inhalt an eine CSV-Datei übergeben. Das Notebook ist im Rahmen der Masterarbeit \"Digitale Erschließung, Analyse und Visualisierung der\n",
    "Handbibliothek von Herzogin Philippine Charlotte von Braunschweig-Lüneburg. Forschungsdatenmanagement in Kooperation\n",
    "zwischen Forschung und Bibliothek.\" im Studiengang Digitales Datenmanagement der FH Potsdam/HU Berlin entstanden.\n",
    "\n",
    "Die nachfolgenden Funktionen sind zum weiteren Verständnis auskommentiert.\n",
    "Ich danke Dario Kampkasper (DK) für seine Expertise und Unterstützung beim Erstellen des Codes.\n",
    "20.02.2023, Henrike Fricke-Steyer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b8a1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import der benötigten Python-Bibliothken\n",
    "import pandas as pd\n",
    "import requests \n",
    "from lxml import etree\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1224cf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1644\n"
     ]
    }
   ],
   "source": [
    "#Einlesen einer Datei mit Identifikationsnummern (IDNs) und Umwandlung der Spalte IDN in Liste die auf dem eigenen \n",
    "#Computer liegt, der Pfad \"C:/...csv\" muss entsprechend ersetzt werden: \n",
    "\n",
    "colnames=['IDN']\n",
    "\n",
    "ns = {\n",
    "    \"pica\": \"info:srw/schema/5/picaXML-v1.0\"\n",
    "}\n",
    "\n",
    "#Einlesen einer Datei mit Identifikationsnummern (IDNs) und Umwandlung der Spalte IDN in Liste die auf dem eigenen \n",
    "#Desktop liegt: \n",
    "data = pd.read_csv(\"C:/...csv\", names=colnames, header=None)\n",
    "idns = data['IDN'].to_list()\n",
    "print(len(idns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6885ff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gekürzte Funktion zur Abfrage der IDNs aus dem SRU-Tutorial (www.dnb.de/dnblabtutorials)\n",
    "#Schleife zur SRU-Abfrage, spricht die Schnittstelle an, Parameter in entsprechender Reihenfolge angepasst\n",
    "def sru(query):\n",
    "    \n",
    "    base_url = \"http://sru.k10plus.de/opac-de-627\"\n",
    "    params = {'version': '1.1',\n",
    "              'operation': 'searchRetrieve',                    \n",
    "              'query': query,\n",
    "              'maximumRecords': '100',\n",
    "              'recordSchema' : 'picaxml'\n",
    "         }\n",
    "    r = requests.get(base_url, params=params)\n",
    "   \n",
    "    ns = {\n",
    "        \"zs\":\"http://www.loc.gov/zing/srw/\",\n",
    "        \"pica\": \"info:srw/schema/5/picaXML-v1.0\"\n",
    "    }\n",
    "    xml = etree.fromstring(r.content)\n",
    "    records = xml.xpath(\"//zs:recordData/pica:record\", namespaces=ns)\n",
    "    \n",
    "    return records\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9e6d64e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1644\n"
     ]
    }
   ],
   "source": [
    "#Übergabe der einzelnen Elemente aus der IDN-Liste an die Funktion, um für jedes Element eine SRU-Abfrage \n",
    "#auszulösen. Die Ergebnisse der einzelnen Abfragen werden als Liste in der Variable \"response\" gespeichert\n",
    "response = [sru(searchtext) for searchtext in idns]\n",
    "\n",
    "#Ausgabe der Anzahl der in der Liste enthaltenen Elemente - diese sollte mit der Anzahl der abgefragten\n",
    "#IDNs übereinstimmen. \n",
    "print (len(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "656ecf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ausgabe der gesammelten Treffer in einer Datei:\n",
    "# 2022-10-21 DK\n",
    "resultTree = etree.ElementTree()\n",
    "recordsElement = etree.Element('records')\n",
    "resultTree._setroot(recordsElement)\n",
    "\n",
    "for record in response: \n",
    "    recordsElement.append(record[0])\n",
    "\n",
    "with open ('data.xml', 'wb',) as f:\n",
    "    resultTree.write(f, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "af6a7d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hilfsfunktion, um ein wiederholbares Fedl abzurufen (inkl. Unterfelder)\n",
    "# 2023-01-21 DK\n",
    "def get_repeatable ( xml, *fields ):\n",
    "    values = []\n",
    "    for field in fields:\n",
    "        xpath = \"pica:datafield[@tag='\" + field + \"']\"\n",
    "        values.extend(xml.xpath(xpath, namespaces=ns))\n",
    "    \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "24e6dde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hilfsfunktion, um für eine Liste von Unterfeldern die Werte abzurufen\n",
    "# 2023-01-21 DK\n",
    "def get_subfields ( xml, subfields ):\n",
    "    values = []\n",
    "    for subfield in subfields:\n",
    "        xpath = \"pica:subfield[@code = '\" + subfield + \"']/text()\"\n",
    "        try:\n",
    "            val = xml.xpath(xpath, namespaces=ns)\n",
    "            values.append(val[0])\n",
    "        except:\n",
    "            \"leer\"\n",
    "    \n",
    "    if len(values):\n",
    "        return values[0]\n",
    "    else:\n",
    "        return \"leer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "326f6fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hilfsfunktion, um Unterfelder gezielt abzurufen\n",
    "# 2023-01-21 DK\n",
    "# Es wird immer nur das erste gefundene zurückgegeben, daher nur für nicht wiederholbare Felder verwenden\n",
    "def get_field ( xml, field, subfields ):\n",
    "    values = []\n",
    "    for subfield in subfields:\n",
    "        xpath = \"pica:datafield[@tag='\" + field + \"']/pica:subfield[@code = '\" + subfield + \"']/text()\"\n",
    "        try:\n",
    "            value = xml.xpath(xpath, namespaces=ns)[0]\n",
    "            values.append(value)\n",
    "        except:\n",
    "            \"leer\"\n",
    "    \n",
    "    try:\n",
    "        return next(value for value in values if value)\n",
    "    except:\n",
    "        \"leer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0b6aad33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraktion entsprechender Inhalte aus den einzelnen Records: \n",
    "# Funktion 2022-10-21 DK\n",
    "\n",
    "def parse_record(record):\n",
    "    xml = record[0]\n",
    "\n",
    "\n",
    "    # bibl. Gattung und Status / 500 \n",
    "    bgs = xml.xpath(\"pica:datafield[@tag='002@']/pica:subfield[@code = '0']\", namespaces=ns)\n",
    "    try:\n",
    "        bgs = bgs[0].text\n",
    "    except:\n",
    "        bgs = ''\n",
    "        \n",
    "    # Erscheinungsjahr / 1100\n",
    "    erj = xml.xpath(\"pica:datafield[@tag='011@']/pica:subfield[@code = 'a']\", namespaces=ns)\n",
    "    try:\n",
    "        erj = erj[0].text\n",
    "    except:\n",
    "        erj = ''\n",
    "        \n",
    "    # Erscheinungsort / 4030\n",
    "    eo = xml.xpath(\"pica:datafield[@tag='033A']/pica:subfield[@code = 'p']\", namespaces=ns)\n",
    "    try:\n",
    "        eo = eo[0].text\n",
    "    except:\n",
    "        eo = ''\n",
    "        \n",
    "    # Erscheinungsort GND-Nummer / 4030\n",
    "    eog = xml.xpath(\"pica:datafield[@tag='033D']/pica:subfield[@code = '7']\", namespaces=ns)\n",
    "    try:\n",
    "        eog = eog[0].text\n",
    "    except:\n",
    "        eog = ''\n",
    "    \n",
    "   # Sprachcode / 1500\n",
    "    spr = xml.xpath(\"pica:datafield[@tag='010@']/pica:subfield[@code = 'a']\", namespaces=ns)\n",
    "    try:\n",
    "        spr = spr[0].text\n",
    "    except:\n",
    "        spr = ''\n",
    "    \n",
    "    # ppn / 100\n",
    "    idn = xml.xpath(\"pica:datafield[@tag='003@']/pica:subfield[@code = '0']\", namespaces=ns)\n",
    "    try:\n",
    "        idn = idn[0].text\n",
    "    except:\n",
    "        idn = ''\n",
    "    \n",
    "    # 2023-01-21 DK:\n",
    "   # → in titelKategorien eine Liste mit den Feldern erstellen und nach Gewichtung sortieren\n",
    "    titelKategorien = [ '021A', '027A', '046C', '036E', '036C' ] # 027A=3260, 046C=4212, 036E=4170–4179, 036C=4150\n",
    "    titelListe = []\n",
    "    for titelKategorie in titelKategorien:\n",
    "        # relevante Unterfelder abrufen\n",
    "        titelFelder = [\n",
    "            get_field(xml, titelKategorie, 'a'),\n",
    "            get_field(xml, titelKategorie, 'd'),\n",
    "            get_field(xml, titelKategorie, 'f')\n",
    "        ]\n",
    "        titelei = [ti.replace('@', '') for ti in titelFelder if ti]\n",
    "        # vorhandene Unterfelder mit ' ; ' zusammensetzen\n",
    "        titelListe.append(\" ; \".join(titelei))\n",
    "    # 2023-01-21 DK Ende\n",
    "\n",
    "    try:\n",
    "        titel = next(sub for sub in titelListe if sub)\n",
    "    except:\n",
    "        titel = \"\"\n",
    "    \n",
    "    # 2021-01-21 DK\n",
    "    \n",
    "    # 028A=3000 wird nicht wiederholt; daher nur eine Abfrage\n",
    "    verfassername = get_field(xml, '028A', ['a', 'A', 'l'])\n",
    "    verfasservorname = get_field(xml, '028A', ['d', 'D', 'P'])\n",
    "    gndverfasser = get_field(xml, '028A', '7')\n",
    "\n",
    "# Weitere Verfasser 028B=3001,3002 können wiederholt werden\n",
    "    weitereVerfKategorien = get_repeatable(xml, '028B')\n",
    "    weitereVerf = []\n",
    "    for kat in weitereVerfKategorien:\n",
    "        weitereVerf.append([\n",
    "            get_subfields(kat, ['a', 'A', 'l']),\n",
    "            get_subfields(kat, ['d', 'D', 'P']),\n",
    "            get_subfields(kat, ['7'])\n",
    "        ])\n",
    "    \n",
    "    vf1n = \"\"\n",
    "    vf1v = \"\"\n",
    "    vf1g = \"\"\n",
    "    vf2n = \"\"\n",
    "    vf2v = \"\"\n",
    "    vf2g = \"\"\n",
    "\n",
    "    try:\n",
    "        vf1n = weitereVerf[0][0]\n",
    "        vf1v = weitereVerf[0][1]\n",
    "        vf1g = weitereVerf[0][2]\n",
    "        vf2n = weitereVerf[1][0]\n",
    "        vf2v = weitereVerf[1][1]\n",
    "        vf2g = weitereVerf[1][2]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "# Sonstige beteiligte Personen 028C=3010, können wiederholt werden\n",
    "    weitereVerfpKategorien = get_repeatable(xml, '028C')\n",
    "    weitereVerfp = []\n",
    "    for kat in weitereVerfpKategorien:\n",
    "        weitereVerfp.append([\n",
    "            get_subfields(kat, ['a', 'A', 'l']),\n",
    "            get_subfields(kat, ['d', 'D', 'P']),\n",
    "            get_subfields(kat, ['7'])\n",
    "        ])\n",
    "    \n",
    "    pvf1n = \"\"\n",
    "    pvf1v = \"\"\n",
    "    pvf1g = \"\"\n",
    "    pvf2n = \"\"\n",
    "    pvf2v = \"\"\n",
    "    pvf2g = \"\"\n",
    "\n",
    "    try:\n",
    "        pvf1n = weitereVerfp[0][0]\n",
    "        pvf1v = weitereVerfp[0][1]\n",
    "        pvf1g = weitereVerfp[0][2]\n",
    "        pvf2n = weitereVerfp[1][0]\n",
    "        pvf2v = weitereVerfp[1][1]\n",
    "        pvf2g = weitereVerfp[1][2]\n",
    "    except:\n",
    "        pass \n",
    "\n",
    " # Sonstige beteiligte Personen, 028G=3050 können wiederholt werden\n",
    "    weiterePersKategorien = get_repeatable(xml, '028G')\n",
    "    weiterePers = []\n",
    "    for kat in weiterePersKategorien:\n",
    "        weiterePers.append([\n",
    "            get_subfields(kat, ['a', 'A', 'l']),\n",
    "            get_subfields(kat, ['d', 'D', 'P']),\n",
    "            get_subfields(kat, ['7'])\n",
    "        ])\n",
    "    \n",
    "    pers1n = \"\"\n",
    "    pers1v = \"\"\n",
    "    pers1g = \"\"\n",
    "    pers2n = \"\"\n",
    "    pers2v = \"\"\n",
    "    pers2g = \"\"\n",
    "     \n",
    "\n",
    "    try:\n",
    "        pers1n = weiterePers[0][0]\n",
    "        pers1v = weiterePers[0][1]\n",
    "        pers1g = weiterePers[0][2]\n",
    "        pers2n = weiterePers[1][0]\n",
    "        pers2v = weiterePers[1][1]\n",
    "        pers2g = weiterePers[1][2]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "       \n",
    "              \n",
    "    \n",
    "    meta_dict = {\n",
    "        \"PPN\":idn,\n",
    "        \"Bibliographische Gattung und Status\":bgs,\n",
    "        \"Sprache\":spr,\n",
    "        \"Erscheinungsjahr\":erj,\n",
    "        \"Erscheinungsort\":eo,\n",
    "        \"Erscheinungsort GND\":eog,\n",
    "        \"Titel\":titel,\n",
    "        \"Verfasservorname\":verfasservorname,\n",
    "        \"Verfassername\":verfassername,\n",
    "        \"GND Verfasser\":gndverfasser,\n",
    "        \"1. Weitere Verfasser Vorname\":vf1v,\n",
    "        \"1. Weitere Verfasser Nachname\":vf1n,\n",
    "        \"1. Weitere Verfasser GND\":vf1g,\n",
    "        \"2. Weitere Verfasser Vorname\":vf2v,\n",
    "        \"2. Weitere Verfasser Nachname\":vf2n,\n",
    "        \"2. Weitere Verfasser GND\":vf2g,\n",
    "        \n",
    "        \"1. Weitere Person Vorname\":pvf1v,\n",
    "        \"1. Weitere Person Nachname\":pvf1n,\n",
    "        \"1. Weitere Person GND\":pvf1g,\n",
    "        \"2. Weitere Person Vorname\":pvf2v,\n",
    "        \"2. Weitere Person Nachname\":pvf2n,\n",
    "        \"2. Weitere Person GND\":pvf2g,\n",
    "        \n",
    "        \"1. Sonstige Person Vorname\":pers1v,\n",
    "        \"1. Sonstige Person Nachname\":pers1n,\n",
    "        \"1. Sonstige Person GND\":pers1g,\n",
    "        \"2. Sonstige Person Vorname\":pers2v,\n",
    "        \"2. Sonstige Person Nachname\":pers2n,\n",
    "        \"2. Sonstige Person GND\":pers2g\n",
    "       \n",
    "    }\n",
    "    \n",
    "    return meta_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c7eb799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Übergabe der einzelnen Records an die Funktion und Ausgabe als DataFrame:\n",
    "output = [parse_record(record) for record in response]\n",
    "\n",
    "# print(output[0])\n",
    "df = pd.DataFrame(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dd1d490d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ausgabe des DataFrames in CSV-Datei\n",
    "df.to_csv('sru_antwort.csv', sep ='\\t') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
